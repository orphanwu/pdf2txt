import time
from cnstd import LayoutAnalyzer
from PIL import Image
import numpy as np
import os
import io
import re
import sys
import shutil
import pdfplumber
import tesserocr
import Levenshtein

# pdfminerç›¸å…³åº“
from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter
from pdfminer.converter import TextConverter
from pdfminer.layout import LAParams
from pdfminer.pdfpage import PDFPage


# pdfè½¬å›¾ç‰‡
def pdf2pic(path):
    pdf = pdfplumber.open(path)
    os.mkdir('./PatentPDF/pic')
    for m in range(len(pdf.pages)):
        page = pdf.pages[m]
        im = page.to_image(resolution=400)
        im.save('./PatentPDF/pic/' + str(m + 1) + '.png')
    pdf.close()


# æ–‡æœ¬æ£€æµ‹å¹¶åˆ‡å‰²æˆå¤šå¼ å›¾ç‰‡
# pathæ˜¯å­˜æ”¾pdfå›¾ç‰‡çš„è·¯å¾„,crop æ˜¯å­˜æ”¾åˆ‡ç‰‡å›¾ç‰‡çš„åœ°æ–¹
def textDetection(path):
    count = 1
    cropPath = './PatentPDF/crop/'
    os.mkdir(cropPath)

    for img_fp in range(len(os.listdir(path))):

        analyzer = LayoutAnalyzer('layout')
        out = analyzer.analyze(path + '/' + str(img_fp + 1) + '.png', resized_shape=704)

        for i in range(len(out)):
            if out[i]['type'] == 'Text' and out[i]['score'] > 0.5:
                out[i]['box'][0] -= 30
                out[i]['box'][2] += 30
                row = tuple(np.concatenate((out[i]['box'][0], out[i]['box'][2]), axis=0))
                # print(row)
                img = Image.open(path + '/' + str(img_fp + 1) + '.png')
                img.crop(row).save(cropPath + str(count) + '.png', 'png')
                count += 1


# å¯¹åˆ‡å‰²çš„å›¾ç‰‡è¿›è¡Œ TesserOCR
# pathæ˜¯ç‰ˆé¢åˆ†æåˆ‡å‰²å¾—åˆ°çš„å›¾ç‰‡
def detectedImgTesserOCR(path):
    text = ''
    for img_path in range(len(os.listdir(path))):
        img_name = str(img_path + 1) + '.png'
        try:
            image = Image.open(os.path.join(path, img_name))
            text += cleanOCR(tesserocr.image_to_text(image))
        except TypeError:
            continue
        text += '\n\n'
    return text


# å¯¹pdfè¿›è¡Œpdfminerè§£æ
# pdfè½¬æ¢
def convert_pdf_to_txt(path):
    rsrcmgr = PDFResourceManager()
    retstr = io.StringIO()
    codec = 'utf-8'
    laparams = LAParams()
    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)
    fp = open(path, 'rb')
    interpreter = PDFPageInterpreter(rsrcmgr, device)
    password = ""
    maxpages = 0
    caching = True
    pagenos = set()
    for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages, password=password, caching=caching,
                                  check_extractable=True):
        interpreter.process_page(page)

    text = retstr.getvalue()

    fp.close()
    device.close()
    retstr.close()
    return text


# æ–‡æœ¬åˆ—è¡¨åŒ–
def Listlize(text):
    list = []
    for li in text.split('\n'):
        if len(li) > 4:
            list.append(li.strip())
    return list


# å¯»æ‰¾æœ€ç›¸ä¼¼çš„å¥å­
def findMostSimilarSentence(line, miner):
    max_similarity = -1
    most_similarity_sentence = line

    for ref in miner:
        distance = Levenshtein.distance(line, ref)
        max_length = max(len(line), len(ref))
        similarity = 1 - distance / max_length

        if similarity > max_similarity:
            max_similarity = similarity
            most_similarity_sentence = ref

    if max_similarity >= 0.5 and 'cid' not in most_similarity_sentence:
        return most_similarity_sentence
    return line


# æ¸…æ´—æ•°æ®
def clean_txt(r):
    cleaned_txt = ''

    # å…ˆè¿›è¡Œæ–‡æœ¬æ ¼å¼è§„èŒƒï¼ŒæŠŠä¸­æ–‡æ ¼å¼å­—ç¬¦è½¬æ¢ä¸ºè‹±æ–‡æ ¼å¼ã€åˆ é™¤ä¸€äº›ä¹±ç å­—ç¬¦ã€è§„èŒƒåŒ–å†…å®¹è¡¨ç¤ºï¼Œdegree åŠ ç‚¹çš„å„ç±»ä¿¡æ¯
    r = r.replace('â€”', '-')
    r = r.replace('M )', 'M=')
    r = r.replace('Å )', 'Å=')
    r = r.replace('Å', 'Î·')
    r = r.replace('Â¢ Â¢', '\'\'')
    r = r.replace('Â¢', '\'')
    r = r.replace('i )', 'i=')
    r = r.replace('25)', 'â‰ˆ')
    r = r.replace('15)', 'ğœ–')
    r = r.replace('No.', 'No')
    r = r.replace('i.e.', 'i e ')
    r = r.replace('e.g. ', 'e g ')
    r = r.replace('e.g.', 'e g')
    r = r.replace('Fig.', 'Fig')
    r = r.replace('Figs.', 'Figs')
    r = r.replace('ref.', 'ref')
    r = r.replace('et al.', 'et al')

    r = r.replace('et. ', 'et ')
    r = r.replace('.ğœ–', '.15)')
    r = r.replace('Â°C', 'degree C')  # åŒ¹é…æ‘„æ°åº¦
    r = r.replace('Â°', ' degree')
    # æ›¿æ¢å¸Œè…Šå­—æ¯
    r = r.replace('Î³', 'gamma')
    r = r.replace('Î²', 'beta')
    r = r.replace('Îµ', 'epsilon')
    r = r.replace('Î±', 'alpha')
    r = r.replace('Î¼', 'mu')

    # åˆ æ‰å¥‡æ€ªçš„å­—ç¬¦
    r = r.replace('â€˜', '')
    r = r.replace('Â´', '')
    r = r.replace('#', '')
    r = r.replace('â‡‘', '')
    r = r.replace('$', '')
    r = r.replace('Î¦', '')
    r = r.replace('Â§', '')
    r = r.replace('Â£', '')
    r = r.replace('â‚¬', '')
    r = r.replace('â€¦', '')
    r = r.replace('Â¥', '')
    r = r.replace('Â®', '')
    r = r.replace('_', '')
    r = r.replace('?', '')
    r = r.replace('Â«', '')
    r = r.replace('Â»', '')
    r = r.replace('@', '')
    r = r.replace('â€ ', '')
    r = r.replace('â€¡', '')
    r = r.replace('â–¡', '')
    r = r.replace('ï¿½', '')
    r = r.replace('ABSTRACT:', '')
    r = r.replace('A B S T R A C T', '')

    sentence_txt = ''
    # æŒ‰ç…§\nåˆ†å‰²æ–‡æœ¬ï¼Œç„¶åè¿›è¡Œå¥å­æ‹¼æ¥
    for sentence in r.split('\n'):
        # æ¸…æ´—æ¯ä¸€è¡Œ
        sentence = sentence.strip()
        if sentence.endswith('.'):
            sentence += ' '
        elif sentence.endswith('-'):
            sentence.rstrip('-')
        # å»é™¤ç´¢å¼•
        sentence = re.sub(r'\[\d+\]', '', sentence)
        sentence = re.sub(r'\[\d+(?:,\d+)*\]', '', sentence)
        sentence = re.sub(r'\[\d+â€“\d+\]', '', sentence)
        sentence = re.sub(r'\[\d+\s*â€“\s*\d+\]', '', sentence)
        sentence = re.sub(r'\[\d+(?:,\d+)*â€“\d+\]', ' ', sentence)
        sentence_txt = sentence_txt + ' ' + sentence

    # æŒ‰ç…§. å¤§å†™å­—æ¯è¿›è¡Œåˆ†å¥
    sentence_txt = sentence_txt.replace('  ', ' ')
    sentence_txt = sentence_txt.replace('  ', ' ')
    sentence_txt = sentence_txt.replace('î„ƒ', '')
    sentence_txt = sentence_txt.replace('î„„', '')
    sentence_txt = sentence_txt.replace('î‚', '')
    sentence_txt = re.sub(r'([a-z]) \. ([A-Z])', r'\1.\n\2', sentence_txt)
    sentence_txt = re.sub(r'([a-z0-9])\. ([A-Z])', r'\1.\n\2', sentence_txt)
    sentence_txt = re.sub(r'(\))\. ([A-Z])', r'\1.\n\2', sentence_txt)
    sentence_txt = re.sub(r'(\) )\. ([A-Z])', r'\1.\n\2', sentence_txt)

    # è¿›è¡Œå¥å­çº§æ¸…æ´—
    for sentence in sentence_txt.split('\n'):
        if len(sentence.split(' ')) < 5:
            continue
        if 'www.' in sentence:
            continue
        if 'http' in sentence:
            continue
        if 'DOI' in sentence:
            continue
        if "doi" in sentence:
            continue
        if "Beijing" in sentence:
            continue
        if "China" in sentence:
            continue
        if "Shanghai" in sentence:
            continue
        if "Zhang" in sentence:
            continue
        if "Liu" in sentence:
            continue
        if "Zhou" in sentence:
            continue
        if "License" in sentence:
            continue
        if 'license' in sentence:
            continue
        if 'licensed' in sentence:
            continue
        if 'conceived' in sentence:
            continue
        if 'paper' in sentence:
            continue
        if 'authors' in sentence:
            continue
        if 'University' in sentence:
            continue
        if 'Province' in sentence:
            continue
        if 'permission' in sentence:
            continue
        if 'review' in sentence:
            continue
        if 'Supervision' in sentence:
            continue
        if 'work' in sentence:
            continue
        if 'Cooperacion' in sentence:
            continue
        if 'supported by' in sentence:
            continue
        if 'E-mail' in sentence:
            continue
        if hasYear(sentence):
            continue
        if mostUpper(sentence):
            continue
        if mostSingeWord(sentence):
            continue

        cleaned_txt = cleaned_txt + sentence + '\n'
    return cleaned_txt


# æ¸…æ´—OCRæ•°æ®
def cleanOCR(text):
    if len(text) < 10:
        return ''
    if len(text.split(' ')) < 5:
        return ''
    if 'Received' in text:
        return ''
    if 'Published' in text:
        return ''
    if 'A R T I C L E I N F O' in text:
        return ''
    if 'References' in text:
        return ''

    return text


# è®¡ç®—æ˜¯ä¸æ˜¯å¤§å¤šæ•°çš„å•è¯æ˜¯å¤§å†™çš„ï¼Œå¦‚æœæœ‰è¶…è¿‡40%çš„å­—ç¬¦æ˜¯å¤§å†™ï¼Œé‚£è‚¯å®šæ˜¯æ— æ•ˆçš„å¥å­
def mostUpper(sentence):
    count = 0
    for char in sentence:
        if char.isupper():
            count += 1
    return True if count / len(sentence) > 0.4 else False


# è®¡ç®—æ˜¯ä¸æ˜¯è¶…è¿‡30%çš„å•è¯æ˜¯å°‘äºä¸‰ä¸ªå­—æ¯çš„
def mostSingeWord(sentence):
    count = 0
    wordList = sentence.split(' ')
    for word in wordList:
        if len(word) < 3:
            count += 1
    return True if count / len(wordList) > 0.3 else False


# åˆ¤æ–­ä¸€å¥è¯æ˜¯å¦å«æœ‰å¹´ä»½
def hasYear(sentence):
    match = re.search(r'\b(19|20)\d{2}\b', sentence)
    return match is not None


if __name__ == '__main__':
    # ä¿è¯ä¸€å®šä¼ é€å‚æ•°äº†,è€Œè¿™é‡Œçš„é¢å¤–å‚æ•°åªå¯èƒ½æœ‰ä¸€ä¸ª
    if 1 == len(sys.argv):
        sys.exit(0)

    # ä¸´æ—¶ç›®å½•
    picTemp = './PatentPDF/pic/'
    cropTemp = './PatentPDF/crop/'

    # pdfè½¬å›¾ç‰‡
    pdf2pic(sys.argv[1])
    # pdfå›¾ç‰‡æ–‡æœ¬æ£€æµ‹
    textDetection(picTemp)

    # OCRè§£æï¼Œè¿”å›åˆ—è¡¨
    OCRContent = Listlize(detectedImgTesserOCR(cropTemp))
    # pdfminerè§£æï¼Œè¿”å›åˆ—è¡¨
    PDFMinerContent = Listlize(convert_pdf_to_txt(sys.argv[1]))

    # ç›¸äº’æ£€éªŒ
    finalTextList = []
    for line in OCRContent:
        finalTextList.append(findMostSimilarSentence(line, PDFMinerContent))

    # åˆ—è¡¨è½¬ä¸ºæ–‡æœ¬
    text = ''
    for txt in finalTextList:
        text = text + txt + '\n'

    # ä¿å­˜æ•°æ®
    #with open(sys.argv[1].split('.pdf')[0] + ' final.txt', 'w', encoding='utf-8') as f:
    output_path = './PatentPDF' + sys.argv[1].split('.pdf')[0] + ' final.txt'
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(clean_txt(text))
        f.close()

    # åˆ é™¤ä¸­é—´æ–‡ä»¶
    shutil.rmtree(picTemp)
    shutil.rmtree(cropTemp)
